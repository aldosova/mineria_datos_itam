{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción a Python para Minería de Datos\n",
    "\n",
    "Este notebook cubre los fundamentos de Python necesarios para minería de datos, incluyendo:\n",
    "\n",
    "1. **Fundamentos de NumPy**: Creación y manipulación de arrays\n",
    "2. **Fundamentos de Pandas**: Manipulación de datos estructurados\n",
    "3. **Iteración**: Cómo iterar sobre diccionarios y listas\n",
    "4. **Visualización**: Creación de gráficas con matplotlib y seaborn\n",
    "5. **Funciones con Type Hints**: Definición de funciones bien documentadas\n",
    "6. **Regresión Lineal**: Implementación y evaluación\n",
    "7. **K-Nearest Neighbors**: Implementación y selección del parámetro k\n",
    "8. **Estimación del Error Real**: Técnicas de validación\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Librerías Necesarias\n",
    "\n",
    "Primero importamos todas las librerías que usaremos en este notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Fundamentos de NumPy\n",
    "\n",
    "NumPy es la librería fundamental para computación científica en Python. Proporciona arrays multidimensionales eficientes.\n",
    "\n",
    "### 2.1 Creación de Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos un array de 100 números igualmente espaciados entre 0 y 10\n",
    "X = np.linspace(0, 10, 100)\n",
    "print(\"Primeros 5 elementos:\", X[:5])\n",
    "print(\"Forma del array:\", X.shape)\n",
    "print(\"Últimos 10 elementos:\", X[90:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Operaciones con Arrays y Generación de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acceso a elementos individuales\n",
    "print(\"Elemento en posición 1:\", X[1])\n",
    "\n",
    "# Generación de datos sintéticos para regresión lineal\n",
    "# y = 0.5*x + 10 + ruido_gaussiano\n",
    "y_linear = 0.5 * X + 10 + np.random.normal(loc=0, scale=1.5, size=100)\n",
    "print(\"Primeros 5 valores de y:\", y_linear[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Fundamentos de Pandas\n",
    "\n",
    "Pandas es la librería principal para manipulación y análisis de datos estructurados en Python.\n",
    "\n",
    "### 3.1 Creación de DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos un DataFrame con nuestros datos\n",
    "df = pd.DataFrame({\"x\": X, \"y\": y_linear})\n",
    "print(\"Primeras 5 filas del DataFrame:\")\n",
    "print(df.head())\n",
    "print(\"\\nInformación del DataFrame:\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Manipulación de DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrado de datos\n",
    "print(\"Filas donde y > 12:\")\n",
    "df_filtrado = df.query(\"y > 12\")\n",
    "print(df_filtrado)\n",
    "\n",
    "# Estadísticas descriptivas\n",
    "print(\"\\nCuantiles de la variable y:\")\n",
    "print(df.y.quantile(q=[0.25, 0.5, 0.75, 0.99]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renombramiento de columnas\n",
    "print(\"Renombrando columnas...\")\n",
    "df_renamed = df.rename(columns={\"x\": \"variable_independiente\", \"y\": \"variable_dependiente\"})\n",
    "print(df_renamed.head())\n",
    "\n",
    "# Volvemos a los nombres originales para el resto del notebook\n",
    "df = df.rename(columns={\"x\": \"x\", \"y\": \"y\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Iteración en Python\n",
    "\n",
    "### 4.1 Iteración sobre Diccionarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo de diccionario con diferentes tipos de datos\n",
    "diccionario_ejemplo = {\n",
    "    \"entero\": 42,\n",
    "    \"array_numpy\": np.array([1, 2, 3, 4]),\n",
    "    \"cadena\": \"minería de datos\",\n",
    "    \"flotante\": 3.14159\n",
    "}\n",
    "\n",
    "# Iteración sobre diccionarios\n",
    "print(\"Iterando sobre el diccionario:\")\n",
    "for clave, valor in diccionario_ejemplo.items():\n",
    "    print(f\"Clave: {clave} | Valor: {valor} | Tipo: {type(valor).__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Iteración sobre Listas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo con lista de números\n",
    "numeros = [1, 4, 9, 16, 25]\n",
    "print(\"Iterando sobre lista de números:\")\n",
    "for i, numero in enumerate(numeros):\n",
    "    print(f\"Posición {i}: {numero}, raíz cuadrada: {np.sqrt(numero):.2f}\")\n",
    "    \n",
    "# Ejemplo con diferentes valores de k para KNN\n",
    "valores_k = [1, 5, 10, 20, 50]\n",
    "print(\"\\nIterando sobre valores de k:\")\n",
    "for k in valores_k:\n",
    "    print(f\"Valor de k: {k}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualización con Matplotlib y Seaborn\n",
    "\n",
    "### 5.1 Gráfica de Dispersión Básica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfica de dispersión básica\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(data=df, x=\"x\", y=\"y\")\n",
    "plt.title(\"Relación entre x y y\")\n",
    "plt.xlabel(\"Variable independiente (x)\")\n",
    "plt.ylabel(\"Variable dependiente (y)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Funciones con Type Hints\n",
    "\n",
    "### 6.1 Función para Generar Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generar_datos_lineales(\n",
    "    n: int = 100,\n",
    "    slope: float = 0.5,\n",
    "    intercept: float = 1.0,\n",
    "    noise_scale: float = 1.5\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Genera datos sintéticos para regresión lineal.\n",
    "    \n",
    "    Parámetros:\n",
    "    -----------\n",
    "    n : int\n",
    "        Número de puntos de datos a generar\n",
    "    slope : float\n",
    "        Pendiente de la relación lineal\n",
    "    intercept : float\n",
    "        Intercepto de la relación lineal\n",
    "    noise_scale : float\n",
    "        Desviación estándar del ruido gaussiano\n",
    "    \n",
    "    Retorna:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        DataFrame con columnas 'x' y 'y'\n",
    "    \"\"\"\n",
    "    X = np.linspace(0, 10, n)\n",
    "    y = slope * X + intercept + np.random.normal(scale=noise_scale, size=n)\n",
    "    return pd.DataFrame({\"x\": X, \"y\": y})\n",
    "\n",
    "# Ejemplo de uso\n",
    "df_nuevo = generar_datos_lineales(n=50, slope=2.0, intercept=5.0)\n",
    "print(\"Datos generados:\")\n",
    "print(df_nuevo.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Función para Visualización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_grafica_dispersion(\n",
    "    data_frame: pd.DataFrame,\n",
    "    x_col: str = \"x\",\n",
    "    y_col: str = \"y\",\n",
    "    titulo: str = \"Gráfica de Dispersión\",\n",
    "    nombre_eje_x: str = \"X\",\n",
    "    nombre_eje_y: str = \"Y\"\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Crea una gráfica de dispersión con formato personalizado.\n",
    "    \n",
    "    Parámetros:\n",
    "    -----------\n",
    "    data_frame : pd.DataFrame\n",
    "        DataFrame que contiene los datos\n",
    "    x_col : str\n",
    "        Nombre de la columna para el eje x\n",
    "    y_col : str\n",
    "        Nombre de la columna para el eje y\n",
    "    titulo : str\n",
    "        Título de la gráfica\n",
    "    nombre_eje_x : str\n",
    "        Etiqueta del eje x\n",
    "    nombre_eje_y : str\n",
    "        Etiqueta del eje y\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.scatterplot(data=data_frame, x=x_col, y=y_col)\n",
    "    plt.title(titulo)\n",
    "    plt.xlabel(nombre_eje_x)\n",
    "    plt.ylabel(nombre_eje_y)\n",
    "    plt.show()\n",
    "\n",
    "# Ejemplo de uso\n",
    "crear_grafica_dispersion(\n",
    "    df_nuevo, \n",
    "    titulo=\"Datos Sintéticos Generados\",\n",
    "    nombre_eje_x=\"Variable Independiente\",\n",
    "    nombre_eje_y=\"Variable Dependiente\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Regresión Lineal\n",
    "\n",
    "### 7.1 Implementación y Ajuste del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generamos datos para trabajar\n",
    "df = generar_datos_lineales(n=1000, slope=1.0, intercept=2.0, noise_scale=1.5)\n",
    "\n",
    "# 1. Crear el modelo de regresión lineal\n",
    "modelo_lr = LinearRegression()\n",
    "\n",
    "# 2. Ajustar el modelo (entrenamiento)\n",
    "# Nota: sklearn necesita X como matriz (2D) y y como vector (1D)\n",
    "X_features = df[[\"x\"]]  # Matriz 2D\n",
    "y_target = df[\"y\"]     # Vector 1D\n",
    "\n",
    "modelo_lr.fit(X_features, y_target)\n",
    "\n",
    "print(f\"Coeficiente (pendiente): {modelo_lr.coef_[0]:.3f}\")\n",
    "print(f\"Intercepto: {modelo_lr.intercept_:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Predicciones y Evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Hacer predicciones\n",
    "y_pred_lr = modelo_lr.predict(X_features)\n",
    "\n",
    "# 4. Evaluar el modelo\n",
    "mse_lr = mean_squared_error(y_target, y_pred_lr)\n",
    "print(f\"Error Cuadrático Medio (MSE): {mse_lr:.3f}\")\n",
    "\n",
    "# Agregar predicciones al DataFrame para visualización\n",
    "df[\"y_pred_lr\"] = y_pred_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Visualización del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización de datos originales y línea de regresión\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=df, x=\"x\", y=\"y\", alpha=0.6, label=\"Datos Originales\")\n",
    "sns.lineplot(data=df, x=\"x\", y=\"y_pred_lr\", color=\"red\", linewidth=2, label=\"Regresión Lineal\")\n",
    "plt.title(\"Regresión Lineal: Datos vs Predicciones\")\n",
    "plt.xlabel(\"Variable Independiente (x)\")\n",
    "plt.ylabel(\"Variable Dependiente (y)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. K-Nearest Neighbors (KNN)\n",
    "\n",
    "### 8.1 Implementación Básica de KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Crear modelo KNN con k=10\n",
    "modelo_knn = KNeighborsRegressor(n_neighbors=10)\n",
    "\n",
    "# 2. Ajustar el modelo\n",
    "modelo_knn.fit(X_features, y_target)\n",
    "\n",
    "# 3. Hacer predicciones\n",
    "y_pred_knn = modelo_knn.predict(X_features)\n",
    "\n",
    "# 4. Evaluar el modelo\n",
    "mse_knn = mean_squared_error(y_target, y_pred_knn)\n",
    "print(f\"MSE KNN (k=10): {mse_knn:.3f}\")\n",
    "print(f\"MSE Regresión Lineal: {mse_lr:.3f}\")\n",
    "\n",
    "# Agregar predicciones al DataFrame\n",
    "df[\"y_pred_knn10\"] = y_pred_knn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 Función para Evaluar Diferentes Valores de K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluar_knn_diferentes_k(\n",
    "    X: pd.DataFrame, \n",
    "    y: pd.Series, \n",
    "    valores_k: list\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Evalúa el rendimiento de KNN para diferentes valores de k.\n",
    "    \n",
    "    Parámetros:\n",
    "    -----------\n",
    "    X : pd.DataFrame\n",
    "        Variables independientes\n",
    "    y : pd.Series\n",
    "        Variable dependiente\n",
    "    valores_k : list\n",
    "        Lista de valores de k a evaluar\n",
    "    \n",
    "    Retorna:\n",
    "    --------\n",
    "    dict\n",
    "        Diccionario con k como clave y MSE como valor\n",
    "    \"\"\"\n",
    "    resultados = {}\n",
    "    \n",
    "    for k in valores_k:\n",
    "        # Crear y ajustar modelo\n",
    "        knn = KNeighborsRegressor(n_neighbors=k)\n",
    "        knn.fit(X, y)\n",
    "        \n",
    "        # Predicciones y evaluación\n",
    "        y_pred = knn.predict(X)\n",
    "        mse = mean_squared_error(y, y_pred)\n",
    "        \n",
    "        resultados[k] = mse\n",
    "        print(f\"k={k}: MSE={mse:.3f}\")\n",
    "    \n",
    "    return resultados\n",
    "\n",
    "# Evaluar diferentes valores de k\n",
    "valores_k = [1, 5, 10, 20, 50, 100]\n",
    "print(\"Evaluando diferentes valores de k:\")\n",
    "resultados_k = evaluar_knn_diferentes_k(X_features, y_target, valores_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3 Visualización de Diferentes Valores de K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear DataFrame para comparar diferentes valores de k\n",
    "df_comparacion = df[[\"x\", \"y\"]].copy()\n",
    "\n",
    "# Agregar predicciones para diferentes valores de k\n",
    "for k in [1, 10, 100]:\n",
    "    knn = KNeighborsRegressor(n_neighbors=k)\n",
    "    knn.fit(X_features, y_target)\n",
    "    df_comparacion[f\"y_pred_k{k}\"] = knn.predict(X_features)\n",
    "\n",
    "# Visualización comparativa\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "for i, k in enumerate([1, 10, 100]):\n",
    "    ax = axes[i]\n",
    "    ax.scatter(df_comparacion[\"x\"], df_comparacion[\"y\"], alpha=0.6, label=\"Datos\")\n",
    "    ax.plot(df_comparacion[\"x\"], df_comparacion[f\"y_pred_k{k}\"], 'r-', linewidth=2, label=f\"KNN k={k}\")\n",
    "    ax.set_title(f\"KNN con k={k}\")\n",
    "    ax.set_xlabel(\"x\")\n",
    "    ax.set_ylabel(\"y\")\n",
    "    ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Selección del Valor Óptimo de K\n",
    "\n",
    "### 9.1 Evaluación Sistemática de K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar un dataset más grande para la evaluación\n",
    "df_grande = generar_datos_lineales(n=1000, slope=2.0, intercept=3.0, noise_scale=2.0)\n",
    "X_grande = df_grande[[\"x\"]]\n",
    "y_grande = df_grande[\"y\"]\n",
    "\n",
    "# Rango de valores k a evaluar\n",
    "max_k = min(200, len(df_grande) // 5)  # k máximo razonable\n",
    "valores_k_rango = np.arange(1, max_k, 10)\n",
    "\n",
    "print(f\"Evaluando k desde 1 hasta {max_k-1} (cada 10 valores)\")\n",
    "print(f\"Total de valores a evaluar: {len(valores_k_rango)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluación de todos los valores de k\n",
    "errores_k = []\n",
    "for k in valores_k_rango:\n",
    "    knn = KNeighborsRegressor(n_neighbors=k)\n",
    "    knn.fit(X_grande, y_grande)\n",
    "    y_pred = knn.predict(X_grande)\n",
    "    mse = mean_squared_error(y_grande, y_pred)\n",
    "    errores_k.append(mse)\n",
    "\n",
    "# Encontrar el k óptimo\n",
    "k_optimo = valores_k_rango[np.argmin(errores_k)]\n",
    "error_minimo = min(errores_k)\n",
    "\n",
    "print(f\"Valor óptimo de k: {k_optimo}\")\n",
    "print(f\"MSE mínimo: {error_minimo:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2 Visualización de la Curva de Error vs K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfica de MSE vs k\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(valores_k_rango, errores_k, 'b-', linewidth=2, marker='o', markersize=4)\n",
    "plt.axvline(x=k_optimo, color='r', linestyle='--', \n",
    "            label=f'k óptimo = {k_optimo}\\nMSE = {error_minimo:.3f}')\n",
    "plt.xlabel('Valor de k')\n",
    "plt.ylabel('Error Cuadrático Medio (MSE)')\n",
    "plt.title('Selección del Valor Óptimo de k en KNN')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Estimación del Error Real\n",
    "\n",
    "### 10.1 División Train-Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar dataset para validación\n",
    "np.random.seed(42)  # Para reproducibilidad\n",
    "df_validacion = generar_datos_lineales(n=2000, slope=1.5, intercept=2.5, noise_scale=2.0)\n",
    "\n",
    "# División train-test\n",
    "X_val = df_validacion[[\"x\"]]\n",
    "y_val = df_validacion[\"y\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_val, y_val, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Datos de entrenamiento: {X_train.shape[0]}\")\n",
    "print(f\"Datos de prueba: {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.2 Función para Evaluación Train-Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluar_modelo_train_test(\n",
    "    X_train: pd.DataFrame,\n",
    "    X_test: pd.DataFrame,\n",
    "    y_train: pd.Series,\n",
    "    y_test: pd.Series,\n",
    "    k: int\n",
    ") -> tuple:\n",
    "    \"\"\"\n",
    "    Evalúa KNN usando división train-test.\n",
    "    \n",
    "    Retorna:\n",
    "    --------\n",
    "    tuple\n",
    "        (error_entrenamiento, error_prueba)\n",
    "    \"\"\"\n",
    "    # Entrenar el modelo\n",
    "    knn = KNeighborsRegressor(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    \n",
    "    # Predicciones\n",
    "    y_train_pred = knn.predict(X_train)\n",
    "    y_test_pred = knn.predict(X_test)\n",
    "    \n",
    "    # Errores\n",
    "    error_train = mean_squared_error(y_train, y_train_pred)\n",
    "    error_test = mean_squared_error(y_test, y_test_pred)\n",
    "    \n",
    "    return error_train, error_test\n",
    "\n",
    "# Evaluar diferentes valores de k\n",
    "valores_k_test = [1, 5, 10, 20, 50, 100]\n",
    "errores_train = []\n",
    "errores_test = []\n",
    "\n",
    "print(\"Evaluación con división train-test:\")\n",
    "print(\"-\" * 40)\n",
    "for k in valores_k_test:\n",
    "    error_train, error_test = evaluar_modelo_train_test(X_train, X_test, y_train, y_test, k)\n",
    "    errores_train.append(error_train)\n",
    "    errores_test.append(error_test)\n",
    "    print(f\"k={k:2d} | Train MSE: {error_train:.3f} | Test MSE: {error_test:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.3 Visualización de Sesgo vs Varianza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfica de error de entrenamiento vs error de prueba\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(valores_k_test, errores_train, 'b-o', linewidth=2, label='Error de Entrenamiento')\n",
    "plt.plot(valores_k_test, errores_test, 'r-o', linewidth=2, label='Error de Prueba')\n",
    "plt.xlabel('Valor de k')\n",
    "plt.ylabel('Error Cuadrático Medio (MSE)')\n",
    "plt.title('Curva de Validación: Error de Entrenamiento vs Error de Prueba')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.yscale('log')  # Escala logarítmica para mejor visualización\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.4 Comparación Final: Regresión Lineal vs KNN Óptimo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encontrar el k óptimo basado en error de prueba\n",
    "k_optimo_test = valores_k_test[np.argmin(errores_test)]\n",
    "print(f\"Valor óptimo de k (basado en error de prueba): {k_optimo_test}\")\n",
    "\n",
    "# Evaluar regresión lineal\n",
    "lr_final = LinearRegression()\n",
    "lr_final.fit(X_train, y_train)\n",
    "y_test_pred_lr = lr_final.predict(X_test)\n",
    "error_test_lr = mean_squared_error(y_test, y_test_pred_lr)\n",
    "\n",
    "# Evaluar KNN óptimo\n",
    "knn_final = KNeighborsRegressor(n_neighbors=k_optimo_test)\n",
    "knn_final.fit(X_train, y_train)\n",
    "y_test_pred_knn = knn_final.predict(X_test)\n",
    "error_test_knn = mean_squared_error(y_test, y_test_pred_knn)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"COMPARACIÓN FINAL - ERROR DE PRUEBA (ESTIMACIÓN REAL)\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Regresión Lineal:        {error_test_lr:.3f}\")\n",
    "print(f\"KNN (k={k_optimo_test}):             {error_test_knn:.3f}\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "if error_test_knn < error_test_lr:\n",
    "    mejora = ((error_test_lr - error_test_knn) / error_test_lr) * 100\n",
    "    print(f\"KNN es mejor por {mejora:.1f}%\")\n",
    "else:\n",
    "    mejora = ((error_test_knn - error_test_lr) / error_test_knn) * 100\n",
    "    print(f\"Regresión Lineal es mejor por {mejora:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumen\n",
    "\n",
    "En este notebook hemos cubierto:\n",
    "\n",
    "1. **NumPy**: Creación y manipulación de arrays para datos numéricos\n",
    "2. **Pandas**: Manipulación de datos estructurados con DataFrames\n",
    "3. **Iteración**: Técnicas para iterar sobre diccionarios y listas\n",
    "4. **Visualización**: Creación de gráficas informativas con matplotlib/seaborn\n",
    "5. **Type Hints**: Definición de funciones bien documentadas y tipadas\n",
    "6. **Regresión Lineal**: Implementación, ajuste y evaluación\n",
    "7. **KNN**: Implementación y comparación de diferentes valores de k\n",
    "8. **Selección de Hiperparámetros**: Técnicas para encontrar el k óptimo\n",
    "9. **Validación**: Estimación del error real usando división train-test\n",
    "\n",
    "### Conceptos Clave Aprendidos:\n",
    "\n",
    "- **Sesgo vs Varianza**: KNN con k pequeño tiene alta varianza, k grande tiene alto sesgo\n",
    "- **Validación**: El error de entrenamiento subestima el error real\n",
    "- **Selección de Modelos**: Comparar diferentes algoritmos usando datos de prueba\n",
    "- **Type Hints**: Mejoran la legibilidad y mantenibilidad del código"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}